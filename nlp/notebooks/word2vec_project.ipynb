{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fb1931-72e6-4602-83bb-40ba5183cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "from gensim.models.phrases import Phraser, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6653a9-2fa4-4cfe-af4e-32266adf10f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       stopped doing that 2 years ago.\\n\\nswitched to...\n",
       "1                 Thank you @iambolajiayo for resharing ðŸ˜Œ\n",
       "2                                            My pleasure~\n",
       "3       Day 63:\\n\\n#100DaysOfCode\\n#hashnode\\n\\nI got ...\n",
       "4                       thank you so much for the article\n",
       "                              ...                        \n",
       "4311    20 Best React Landing Page Templates\\n{ by Ale...\n",
       "4312    @hashnode: Check out my developer blog.  https...\n",
       "4313    DAY 13 OF #100DAYSOFGADS2020\\n{ by Moseti Zach...\n",
       "4314    Ahhhhhh... You followed me sha! ðŸ¤£ðŸ¤£ðŸ¤£...\\n\\nI'm ...\n",
       "4315                                                  ðŸ˜ŒðŸ˜ŒðŸ˜Œ\n",
       "Name: tweet, Length: 4316, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Tweets\n",
    "\n",
    "df = pd.read_csv(\"../data/tweets.csv\")\n",
    "\n",
    "df[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323c7927-775e-4598-b789-6954eb708fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaccum_cleaner(tweet):\n",
    "    p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER, p.OPT.RESERVED)\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = re.sub(r\"[^a-z0-9]\",' ',tweet.lower())\n",
    "    tweet = remove_stopwords(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61776e88-9632-47f3-a153-74942c5a0182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_tweet\"] = df[\"tweet\"].map(vaccum_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a92a7c0-4e6c-4fe6-a299-f6a8ff0d6a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['stopped',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'switched',\n",
       "  'markdown',\n",
       "  'articles',\n",
       "  'source',\n",
       "  'code'],\n",
       " ['thank', 'resharing'],\n",
       " ['pleasure'],\n",
       " ['day',\n",
       "  '100daysofcode',\n",
       "  'hashnode',\n",
       "  'got',\n",
       "  'fed',\n",
       "  'coding',\n",
       "  'got',\n",
       "  'stuck',\n",
       "  'problem',\n",
       "  'past',\n",
       "  'days',\n",
       "  't',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'coding',\n",
       "  't',\n",
       "  'understand',\n",
       "  'flow',\n",
       "  'instead',\n",
       "  'wasting',\n",
       "  'time',\n",
       "  'switched',\n",
       "  'writing',\n",
       "  'blog'],\n",
       " ['thank', 'article']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training word embedding models, a list of sentences, where each sentence is a list of words is created.\n",
    "all_sentences = []\n",
    "for tweet in df[\"clean_tweet\"]:\n",
    "    words = tweet.split(\" \")\n",
    "    all_sentences.append(words)\n",
    "all_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff50d866-2a0c-4aca-87e5-44616825ef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['stopped',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'switched',\n",
       "  'markdown',\n",
       "  'articles',\n",
       "  'source',\n",
       "  'code'],\n",
       " ['thank', 'resharing'],\n",
       " ['pleasure'],\n",
       " ['day',\n",
       "  '100daysofcode',\n",
       "  'hashnode',\n",
       "  'got',\n",
       "  'fed',\n",
       "  'coding',\n",
       "  'got',\n",
       "  'stuck',\n",
       "  'problem',\n",
       "  'past',\n",
       "  'days',\n",
       "  't',\n",
       "  'feel_like',\n",
       "  'coding',\n",
       "  't',\n",
       "  'understand',\n",
       "  'flow',\n",
       "  'instead',\n",
       "  'wasting',\n",
       "  'time',\n",
       "  'switched',\n",
       "  'writing',\n",
       "  'blog'],\n",
       " ['thank', 'article'],\n",
       " ['non',\n",
       "  'podcast',\n",
       "  'developer',\n",
       "  'hosting',\n",
       "  'personal',\n",
       "  'giveaway',\n",
       "  'announcement'],\n",
       " ['famous',\n",
       "  'podcasts',\n",
       "  'tech',\n",
       "  'webdevelopment',\n",
       "  'technology',\n",
       "  '2articles1week',\n",
       "  'beginners',\n",
       "  'codenewbies1'],\n",
       " ['congratulations', 'ruth'],\n",
       " ['positively',\n",
       "  'lost',\n",
       "  'damon',\n",
       "  'schulz',\n",
       "  'quick',\n",
       "  'piece',\n",
       "  'short',\n",
       "  'path',\n",
       "  'brought',\n",
       "  'developer',\n",
       "  'juniordeveloper',\n",
       "  'javascript',\n",
       "  'learning',\n",
       "  'education'],\n",
       " ['thinking',\n",
       "  'blogging',\n",
       "  'long',\n",
       "  'time',\n",
       "  'couldn',\n",
       "  't',\n",
       "  'finally',\n",
       "  'started',\n",
       "  'blog',\n",
       "  'introduction',\n",
       "  'write',\n",
       "  'second',\n",
       "  'probably',\n",
       "  'weekend',\n",
       "  'check',\n",
       "  '100daysofcode',\n",
       "  'firstblog']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "phrases = Phrases(all_sentences, min_count=5, threshold=2)\n",
    "bigram = Phraser(phrases)\n",
    "all_sentences = list(bigram[all_sentences])\n",
    "all_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1911a2a-5819-4c5a-8dd9-45ad9e3780a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(all_sentences, min_count=15,  workers=4, window=5, epochs=100)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966ac59e-356a-406e-ae0c-44653101795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding some analogies\n",
      "                0                1\n",
      "0  webdevelopment  machinelearning\n",
      "1          nodejs          python3\n",
      "2       beginners          python3\n",
      "3  2articles1week          python3\n",
      "4         restapi  machinelearning\n",
      "----------\n",
      "                0                1\n",
      "0  webdevelopment  machinelearning\n",
      "1          nodejs          python3\n",
      "2       beginners          python3\n",
      "3  2articles1week          python3\n",
      "4         restapi          python3\n",
      "----------\n",
      "Finding some similarities\n",
      "[('python3', 0.7117981910705566), ('machinelearning', 0.610938549041748), ('datascience', 0.5108599066734314), ('devblogging', 0.4940609037876129), ('django', 0.4740975797176361), ('beginner', 0.46559756994247437), ('2articles1week', 0.36954450607299805), ('stuff', 0.3520037531852722), ('java', 0.34186333417892456), ('womenwhocode', 0.3401317000389099), ('different', 0.34008634090423584), ('coding', 0.3388567864894867), ('data', 0.3375648260116577), ('2articles1week_javascript', 0.33489835262298584), ('datastructures', 0.33389243483543396), ('codenewbies', 0.32988032698631287), ('project', 0.329571396112442), ('newbie', 0.328275591135025), ('2articles1week_hashnode', 0.31591343879699707), ('sideproject', 0.299907386302948)]\n",
      "----------\n",
      "[('webdesign', 0.5839792490005493), ('html5_css3', 0.5495849847793579), ('2articles1week_javascript', 0.5473966598510742), ('100daysofcode_codenewbie', 0.5425178408622742), ('frontenddevelopment', 0.5391740202903748), ('webdevelopment', 0.5301265120506287), ('reactjs', 0.5242940783500671), ('es6', 0.5175598859786987), ('js', 0.5143395662307739), ('womenwhocode', 0.5061072707176208), ('node', 0.5000427961349487), ('typescript', 0.4974175691604614), ('reactjs_javascript', 0.4794957935810089), ('beginners', 0.46380165219306946), ('array', 0.4605574607849121), ('basics', 0.4574120044708252), ('vuejs', 0.45723506808280945), ('100daysofcode', 0.4489508867263794), ('html', 0.43990764021873474), ('react', 0.43495306372642517)]\n"
     ]
    }
   ],
   "source": [
    "def pp(obj):\n",
    "    print(pd.DataFrame(obj))\n",
    "    \n",
    "def analogy(worda, wordb, wordc):\n",
    "    result = model.wv.most_similar(negative=[worda], \n",
    "                                positive=[wordb, wordc])\n",
    "    return result[0][0]\n",
    "print(\"Finding some analogies\")\n",
    "keywords = ['webdevelopment', 'nodejs', \"beginners\", \"2articles1week\",\"restapi\"]\n",
    "answers = [analogy('js', 'python', kw) for kw in keywords]\n",
    "pp(zip(keywords,answers))\n",
    "print(\"-\"*10)\n",
    "answers = [analogy('javascript', 'python', kw) for kw in keywords]\n",
    "pp(zip(keywords,answers))\n",
    "print(\"-\"*10)\n",
    "print(\"Finding some similarities\")\n",
    "print(model.wv.most_similar(\"python\", topn=20))\n",
    "print(\"-\"*10)\n",
    "print(model.wv.most_similar(\"javascript\", topn=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd02310b29dc1dc5ec74e8e4640e6baf2a33fc38d279132d436ab31258a1c4e1d90"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "2310b29dc1dc5ec74e8e4640e6baf2a33fc38d279132d436ab31258a1c4e1d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
